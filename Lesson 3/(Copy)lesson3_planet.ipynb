{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "(Copy)lesson3-planet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amannarsaria4/fast.ai/blob/master/Lesson%203/(Copy)lesson3_planet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkrA12VXb-N3",
        "colab_type": "text"
      },
      "source": [
        "## Multi-label prediction with Planet Amazon dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZe4an8Cb-N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJPGTPvtb-OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmcVqyM0b-OO",
        "colab_type": "text"
      },
      "source": [
        "## Getting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92-QJJqBb-OP",
        "colab_type": "text"
      },
      "source": [
        "The planet dataset isn't available on the [fastai dataset page](https://course.fast.ai/datasets) due to copyright restrictions. You can download it from Kaggle however. Let's see how to do this by using the [Kaggle API](https://github.com/Kaggle/kaggle-api) as it's going to be pretty useful to you if you want to join a competition or use other Kaggle datasets later on.\n",
        "\n",
        "First, install the Kaggle API by uncommenting the following line and executing it, or by executing it in your terminal (depending on your platform you may need to modify this slightly to either add `source activate fastai` or similar, or prefix `pip` with a path. Have a look at how `conda install` is called for your platform in the appropriate *Returning to work* section of https://course.fast.ai/. (Depending on your environment, you may also need to append \"--user\" to the command.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51LsyXRyb-OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "a702da25-8947-48fc-da0d-9e355422ed1d"
      },
      "source": [
        " ! {sys.executable} -m pip install kaggle --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/pkgutil.py\", line 412, in get_importer\n",
            "    importer = sys.path_importer_cache[path_item]\n",
            "KeyError: ''\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/__main__.py\", line 16, in <module>\n",
            "    from pip._internal.main import main as _main  # isort:skip # noqa\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/main.py\", line 13, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/autocompletion.py\", line 11, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/cmdoptions.py\", line 28, in <module>\n",
            "    from pip._internal.models.target_python import TargetPython\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/models/target_python.py\", line 4, in <module>\n",
            "    from pip._internal.utils.misc import normalize_version_info\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/misc.py\", line 19, in <module>\n",
            "    from pip._vendor import pkg_resources\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3250, in <module>\n",
            "    @_call_aside\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3234, in _call_aside\n",
            "    f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3263, in _initialize_master_working_set\n",
            "    working_set = WorkingSet._build_master()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 574, in _build_master\n",
            "    ws = cls()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 567, in __init__\n",
            "    self.add_entry(entry)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 623, in add_entry\n",
            "    for dist in find_distributions(entry, True):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1969, in find_distributions\n",
            "    importer = get_importer(path_item)\n",
            "  File \"/usr/lib/python3.6/pkgutil.py\", line 416, in get_importer\n",
            "    importer = path_hook(path_item)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1324, in path_hook_for_FileFinder\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 102, in _path_isdir\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCheqPijb-OW",
        "colab_type": "text"
      },
      "source": [
        "Then you need to upload your credentials from Kaggle on your instance. Login to kaggle and click on your profile picture on the top left corner, then 'My account'. Scroll down until you find a button named 'Create New API Token' and click on it. This will trigger the download of a file named 'kaggle.json'.\n",
        "\n",
        "Upload this file to the directory this notebook is running in, by clicking \"Upload\" on your main Jupyter page, then uncomment and execute the next two commands (or run them in a terminal). For Windows, uncomment the last two commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvktsR6Hb-OX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "827b59f1-132d-430a-b56e-a7cfe399c9ea"
      },
      "source": [
        "! mkdir -p ~/.kaggle/\n",
        "! mv kaggle.json ~/.kaggle/\n",
        "\n",
        "#For Windows, uncomment these two commands\n",
        "! mkdir %userprofile%\\.kaggle\n",
        "! move kaggle.json %userprofile%\\.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "mkdir: cannot create directory ‘%userprofile%.kaggle’: File exists\n",
            "/bin/bash: move: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA4V9X9sb-Oj",
        "colab_type": "text"
      },
      "source": [
        "You're all set to download the data from [planet competition](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space). You **first need to go to its main page and accept its rules**, and run the two cells below (uncomment the shell commands to download and unzip the data). If you get a `403 forbidden` error it means you haven't accepted the competition rules yet (you have to go to the competition page, click on *Rules* tab, and then scroll to the bottom to find the *accept* button)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2_1LO8Hb-On",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f20b71a-8d48-448a-eb4f-c79194885af6"
      },
      "source": [
        "path = Config.data_path()/'planet'\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/planet')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8pKJwzgauV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUUP6uPEb-O1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a737ac8e-dfe9-40ec-8876-05e043bc57ff"
      },
      "source": [
        " ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z -p {path}  \n",
        " ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv -p {path}  \n",
        " ! unzip -q -n {path}/train_v2.csv.zip -d {path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404 - Not Found\n",
            "404 - Not Found\n",
            "unzip:  cannot find or open {path}/train_v2.csv.zip, {path}/train_v2.csv.zip.zip or {path}/train_v2.csv.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4uSPStob-O-",
        "colab_type": "text"
      },
      "source": [
        "To extract the content of this file, we'll need 7zip, so uncomment the following line if you need to install it (or run `sudo apt install p7zip-full` in your terminal)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBISF9bSb-PA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "536d0cb0-8ba7-4278-ef51-1e1519a55f07"
      },
      "source": [
        "! conda install --yes --prefix {sys.prefix} -c haasad eidl7zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPEYEqI9b-PJ",
        "colab_type": "text"
      },
      "source": [
        "And now we can unpack the data (uncomment to run - this might take a few minutes to complete)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t03mPafYb-PK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! 7za -bd -y -so x {path}/train-jpg.tar.7z | tar xf - -C {path.as_posix()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyV8mYADb-PQ",
        "colab_type": "text"
      },
      "source": [
        "## Multiclassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsB0ZzLLb-PR",
        "colab_type": "text"
      },
      "source": [
        "Contrary to the pets dataset studied in last lesson, here each picture can have multiple labels. If we take a look at the csv file containing the labels (in 'train_v2.csv' here) we see that each 'image_name' is associated to several tags separated by spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTghbgVb-PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/root/.fastai/data/planet/train_v2.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXR0cTJkb-Pc",
        "colab_type": "text"
      },
      "source": [
        "To put this in a `DataBunch` while using the [data block API](https://docs.fast.ai/data_block.html), we then need to using `ImageList` (and not `ImageDataBunch`). This will make sure the model created has the proper loss function to deal with the multiple classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2fucC-b-Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEFjKwA4b-Pj",
        "colab_type": "text"
      },
      "source": [
        "We use parentheses around the data block pipeline below, so that we can use a multiline statement without needing to add '\\\\'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr9BzsY2b-Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "src = (ImageList.from_csv(path, 'train_v2.csv', folder='train-jpg', suffix='.jpg')\n",
        "       .split_by_rand_pct(0.2)\n",
        "       .label_from_df(label_delim=' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7-rqxdyb-Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (src.transform(tfms, size=128)\n",
        "        .databunch().normalize(imagenet_stats))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbpcGM6-b-Pv",
        "colab_type": "text"
      },
      "source": [
        "`show_batch` still works, and show us the different labels separated by `;`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjnu-McTb-Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.show_batch(rows=3, figsize=(12,9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E86dcEMb-P2",
        "colab_type": "text"
      },
      "source": [
        "To create a `Learner` we use the same function as in lesson 1. Our base architecture is resnet50 again, but the metrics are a little bit differeent: we use `accuracy_thresh` instead of `accuracy`. In lesson 1, we determined the predicition for a given class by picking the final activation that was the biggest, but here, each activation can be 0. or 1. `accuracy_thresh` selects the ones that are above a certain threshold (0.5 by default) and compares them to the ground truth.\n",
        "\n",
        "As for Fbeta, it's the metric that was used by Kaggle on this competition. See [here](https://en.wikipedia.org/wiki/F1_score) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DsNP0Pib-P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch = models.resnet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HCs3xyqb-P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_02 = partial(accuracy_thresh, thresh=0.2)\n",
        "f_score = partial(fbeta, thresh=0.2)\n",
        "learn = cnn_learner(data, arch, metrics=[acc_02, f_score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhyYJjWub-QE",
        "colab_type": "text"
      },
      "source": [
        "We use the LR Finder to pick a good learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYSAcTQFb-QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5au4nQDxb-QL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "970xAjOpb-QP",
        "colab_type": "text"
      },
      "source": [
        "Then we can fit the head of our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5RhLWSmb-QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DgUTpmTb-QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(5, slice(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EscsSC5lb-Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('stage-1-rn50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i3AD7fib-Qg",
        "colab_type": "text"
      },
      "source": [
        "...And fine-tune the whole model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vs53v7Lb-Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nD_eMl-b-Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOlgh4iMb-Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZivXUtmb-Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('stage-2-rn50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U9nPPuIb-Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (src.transform(tfms, size=256)\n",
        "        .databunch().normalize(imagenet_stats))\n",
        "\n",
        "learn.data = data\n",
        "data.train_ds[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I8f0QX9b-Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ2j3MjQb-Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW3sUVFab-RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=1e-2/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCgjvLUKb-RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(5, slice(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReC3SSW5b-RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('stage-1-256-rn50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmZm6v5xb-RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ3985-Zb-RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL-L9hG4b-Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.recorder.plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eryxUzrUb-Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('stage-2-256-rn50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXOUTnB_b-Rq",
        "colab_type": "text"
      },
      "source": [
        "You won't really know how you're going until you submit to Kaggle, since the leaderboard isn't using the same subset as we have for training. But as a guide, 50th place (out of 938 teams) on the private leaderboard was a score of `0.930`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8XiHEiDb-Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cR3pJSlb-Rv",
        "colab_type": "text"
      },
      "source": [
        "## fin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nazg-aKLb-Rw",
        "colab_type": "text"
      },
      "source": [
        "(This section will be covered in part 2 - please don't ask about it just yet! :) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sont8SX2b-Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg.tar.7z -p {path}  \n",
        "#! 7za -bd -y -so x {path}/test-jpg.tar.7z | tar xf - -C {path}\n",
        "#! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg-additional.tar.7z -p {path}  \n",
        "#! 7za -bd -y -so x {path}/test-jpg-additional.tar.7z | tar xf - -C {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP-LieuHb-R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = ImageList.from_folder(path/'test-jpg').add(ImageList.from_folder(path/'test-jpg-additional'))\n",
        "len(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AidZ0Hfjb-R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = load_learner(path, test=test)\n",
        "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jklmsjhlb-SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresh = 0.2\n",
        "labelled_preds = [' '.join([learn.data.classes[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhU6acO6b-SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelled_preds[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_JevqJMb-SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnames = [f.name[:-4] for f in learn.data.test_ds.items]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGO3qyjOb-SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'image_name':fnames, 'tags':labelled_preds}, columns=['image_name', 'tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnX6AQ_gb-Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(path/'submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4PfcvwIb-Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle competitions submit planet-understanding-the-amazon-from-space -f {path/'submission.csv'} -m \"My submission\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPZwiZUUb-So",
        "colab_type": "text"
      },
      "source": [
        "Private Leaderboard score: 0.9296 (around 80th)"
      ]
    }
  ]
}